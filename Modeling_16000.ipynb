{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ph1lipXu/Biotechnological-Ecosystem-Service-Replacement-Research/blob/main/Modeling_16000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "jx_vlHyX_UCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow nltk scikit-learn\n",
        "#!pip install gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, SimpleRNN, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import gensim\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "pd.options.display.max_columns = 20\n",
        "pd.options.display.max_rows = 20\n",
        "pd.options.display.max_colwidth = 80\n",
        "np.set_printoptions(precision = 4, suppress = True)"
      ],
      "metadata": {
        "id": "wZAGxndo_YKM",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrqfA4dE_QDL",
        "outputId": "8277fc0a-5deb-48a6-d3fd-6a6d97d4aae7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-10 19:50:01--  https://raw.githubusercontent.com/Ph1lipXu/Machine-Learning-on-Suicide-and-Depression-Detection/refs/heads/main/data/cleaned_data_16000.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36085156 (34M) [text/plain]\n",
            "Saving to: ‘cleaned_data_16000.csv’\n",
            "\n",
            "cleaned_data_16000. 100%[===================>]  34.41M   112MB/s    in 0.3s    \n",
            "\n",
            "2025-04-10 19:50:03 (112 MB/s) - ‘cleaned_data_16000.csv’ saved [36085156/36085156]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Ph1lipXu/Machine-Learning-on-Suicide-and-Depression-Detection/refs/heads/main/data/cleaned_data_16000.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/cleaned_data_16000.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IWg9ccPYY68k",
        "outputId": "c8870aa3-3593-4682-f803-b20a6436cd83"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                              text  \\\n",
              "0  can i get some support please...so i am not as depressed as i used to be (i ...   \n",
              "1  everything is going wrong .i have been trying not to drink, but everyone is ...   \n",
              "2                                                     i am done fighting it.*gone*   \n",
              "3  today i cut my hairmy hair has always been a thick mess of curls that went a...   \n",
              "4  i do not know what to do and i have no hopes for the future.it is kinda toug...   \n",
              "\n",
              "        class  \\\n",
              "0  depression   \n",
              "1  depression   \n",
              "2  depression   \n",
              "3  depression   \n",
              "4  depression   \n",
              "\n",
              "                                                                            tokens  \n",
              "0  ['can', 'I', 'get', 'some', 'support', 'please', 'so', 'I', 'be', 'not', 'as...  \n",
              "1  ['everything', 'be', 'go', 'wrong', 'have', 'be', 'try', 'not', 'to', 'drink...  \n",
              "2                                           ['I', 'be', 'do', 'fight', 'it', 'go']  \n",
              "3  ['today', 'I', 'cut', 'my', 'hairmy', 'hair', 'have', 'always', 'be', 'a', '...  \n",
              "4  ['I', 'do', 'not', 'know', 'what', 'to', 'do', 'and', 'I', 'have', 'no', 'ho...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aff04612-50f3-4fc4-ae3c-44db0d21095b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>can i get some support please...so i am not as depressed as i used to be (i ...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['can', 'I', 'get', 'some', 'support', 'please', 'so', 'I', 'be', 'not', 'as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>everything is going wrong .i have been trying not to drink, but everyone is ...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['everything', 'be', 'go', 'wrong', 'have', 'be', 'try', 'not', 'to', 'drink...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i am done fighting it.*gone*</td>\n",
              "      <td>depression</td>\n",
              "      <td>['I', 'be', 'do', 'fight', 'it', 'go']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>today i cut my hairmy hair has always been a thick mess of curls that went a...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['today', 'I', 'cut', 'my', 'hairmy', 'hair', 'have', 'always', 'be', 'a', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i do not know what to do and i have no hopes for the future.it is kinda toug...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['I', 'do', 'not', 'know', 'what', 'to', 'do', 'and', 'I', 'have', 'no', 'ho...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aff04612-50f3-4fc4-ae3c-44db0d21095b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aff04612-50f3-4fc4-ae3c-44db0d21095b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aff04612-50f3-4fc4-ae3c-44db0d21095b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bd08333b-3384-4ea9-b471-cba09031f798\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd08333b-3384-4ea9-b471-cba09031f798')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bd08333b-3384-4ea9-b471-cba09031f798 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12918,\n        \"samples\": [\n          \"i cannot go through with iti have made the decision 4 ti ames, yet every ti ame i seem to back out last minute. i was so sure i would go through with it this ti ame, too. i quit my job, broke up with boyfriend, deleted most of my social media accounts, i was ready to just end it all. yet for some reason i still cannot work up the courage. currently parked off the road next to a bridge because i am scared and do not know what to do.\",\n          \"anyone wanna get married ? bc you can only have sex after marriage  flushed_face \",\n          \"this saturdaythat would be a good day for it. ive finally escaped peoples birthdays, so i neednt worry about that. i just need to get things settled by then.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"SuicideWatch\",\n          \"noise\",\n          \"depression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12908,\n        \"samples\": [\n          \"['at', 'what', 'ti', 'ame', 'do', 'you', 'usually', 'workout', 'personally', 'I', 'just', 'try', 'to', 'be', 'randomly', 'active', 'throughout', 'the', 'day', 'cause', 'I', 'do', 'not', 'know', 'how', 'to', 'focus', 'myself', 'into', 'a', 'workout', 'most', 'of', 'the', 'ti', 'ame', 'which', 'be', 'really', 'I', 'amportant', 'to', 'I', 'because', 'constantly', 'force', 'yourself', 'to', 'do', 'something', 'take', 'a', 'huge', 'toll', 'on', 'your', 'mental', 'health', 'I', 'have', 'try', 'to', 'get', 'into', 'moright', 'nowe', 'workout', 'but', 'I', 'be', 'never', 'feel', 'it', 'or', 'I', 'sleep', 'in', 'usually', 'I', 'start', 'around', 'so', 'I', 'can', 'sleep', 'like', 'the', 'dead', 'even', 'thoughugh', 'they', 'say', 'you', 'should', 'not', 'do', 'that', 'but', 'I', 'be', 'type', 'this', 'at', 'am', 'because', 'I', 'mess', 'up', 'my', 'sleep', 'schedule', 'in', 'the', 'past', 'week', 'I', 'be', 'wonder', 'if', 'I', 'should', 'use', 'this', 'opportunity', 'to', 'try', 'and', 'start', 'a', 'moright', 'nowing', 'routine', 'again']\",\n          \"['anyone', 'wan', 'na', 'make', 'a', 'discord', 'server', 'together', 'it', 'can', 'be', 'about', 'whatever', 'you', 'want', 'I', 'be', 'just', 'that', 'bored', 'really']\",\n          \"['I', 'make', 'this', 'survey', 'on', 'social', 'comparison', 'and', 'in', 'psychology', 'hey', 'I', 'be', 'do', 'an', 'anonymous', 'survey', 'about', 'social', 'comparison', 'and', 'as', 'a', 'task', 'in', 'psychology', 'class', 'I', 'would', 'greatly', 'appreciate', 'if', 'anybody', 'would', 'like', 'to', 'participate', 'thank', 'in', 'advance', 'link', 'https']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHw9aZRJ7aBI"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['suicide_class'] = df['class'].apply(lambda x: 'suicide' if x == 'SuicideWatch' else 'nonsuicide')\n",
        "df['depression_class'] = df['class'].apply(lambda x: 'depression' if x == 'depression' else 'nondepression')\n",
        "df['teenager_class'] = df['class'].apply(lambda x: 'teenager' if x == 'teenagers' else 'nonteenager')"
      ],
      "metadata": {
        "id": "RvGbnNesc6-N"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "mnf7KB_cc8Mu",
        "outputId": "1c1a5104-b43f-477e-95b7-cc4be97191d6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                              text  \\\n",
              "0  can i get some support please...so i am not as depressed as i used to be (i ...   \n",
              "1  everything is going wrong .i have been trying not to drink, but everyone is ...   \n",
              "2                                                     i am done fighting it.*gone*   \n",
              "3  today i cut my hairmy hair has always been a thick mess of curls that went a...   \n",
              "4  i do not know what to do and i have no hopes for the future.it is kinda toug...   \n",
              "5  tired of life, tired of living. do not know what to do hey guys, \\n\\ni am 16...   \n",
              "6  what is one concrete thing that has helped you in your battle against depres...   \n",
              "7  does mental health go hand in hand with the physical health?when i feel at m...   \n",
              "8  the thing that hurts the most is knowing that i have been through worse.when...   \n",
              "9  need someone to talk toi am a guy in high school and i just need to talk to ...   \n",
              "\n",
              "        class  \\\n",
              "0  depression   \n",
              "1  depression   \n",
              "2  depression   \n",
              "3  depression   \n",
              "4  depression   \n",
              "5  depression   \n",
              "6  depression   \n",
              "7  depression   \n",
              "8  depression   \n",
              "9  depression   \n",
              "\n",
              "                                                                            tokens  \\\n",
              "0  ['can', 'I', 'get', 'some', 'support', 'please', 'so', 'I', 'be', 'not', 'as...   \n",
              "1  ['everything', 'be', 'go', 'wrong', 'have', 'be', 'try', 'not', 'to', 'drink...   \n",
              "2                                           ['I', 'be', 'do', 'fight', 'it', 'go']   \n",
              "3  ['today', 'I', 'cut', 'my', 'hairmy', 'hair', 'have', 'always', 'be', 'a', '...   \n",
              "4  ['I', 'do', 'not', 'know', 'what', 'to', 'do', 'and', 'I', 'have', 'no', 'ho...   \n",
              "5  ['tired', 'of', 'life', 'tired', 'of', 'live', 'do', 'not', 'know', 'what', ...   \n",
              "6  ['what', 'be', 'one', 'concrete', 'thing', 'that', 'have', 'help', 'you', 'i...   \n",
              "7  ['do', 'mental', 'health', 'go', 'hand', 'in', 'hand', 'with', 'the', 'physi...   \n",
              "8  ['the', 'thing', 'that', 'hurt', 'the', 'most', 'be', 'know', 'that', 'I', '...   \n",
              "9  ['need', 'someone', 'to', 'talk', 'toi', 'be', 'a', 'guy', 'in', 'high', 'sc...   \n",
              "\n",
              "  suicide_class depression_class teenager_class  \n",
              "0    nonsuicide       depression    nonteenager  \n",
              "1    nonsuicide       depression    nonteenager  \n",
              "2    nonsuicide       depression    nonteenager  \n",
              "3    nonsuicide       depression    nonteenager  \n",
              "4    nonsuicide       depression    nonteenager  \n",
              "5    nonsuicide       depression    nonteenager  \n",
              "6    nonsuicide       depression    nonteenager  \n",
              "7    nonsuicide       depression    nonteenager  \n",
              "8    nonsuicide       depression    nonteenager  \n",
              "9    nonsuicide       depression    nonteenager  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac1434ff-3d4e-44e0-a9d0-5503bafce511\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "      <th>tokens</th>\n",
              "      <th>suicide_class</th>\n",
              "      <th>depression_class</th>\n",
              "      <th>teenager_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>can i get some support please...so i am not as depressed as i used to be (i ...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['can', 'I', 'get', 'some', 'support', 'please', 'so', 'I', 'be', 'not', 'as...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>everything is going wrong .i have been trying not to drink, but everyone is ...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['everything', 'be', 'go', 'wrong', 'have', 'be', 'try', 'not', 'to', 'drink...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i am done fighting it.*gone*</td>\n",
              "      <td>depression</td>\n",
              "      <td>['I', 'be', 'do', 'fight', 'it', 'go']</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>today i cut my hairmy hair has always been a thick mess of curls that went a...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['today', 'I', 'cut', 'my', 'hairmy', 'hair', 'have', 'always', 'be', 'a', '...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i do not know what to do and i have no hopes for the future.it is kinda toug...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['I', 'do', 'not', 'know', 'what', 'to', 'do', 'and', 'I', 'have', 'no', 'ho...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tired of life, tired of living. do not know what to do hey guys, \\n\\ni am 16...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['tired', 'of', 'life', 'tired', 'of', 'live', 'do', 'not', 'know', 'what', ...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>what is one concrete thing that has helped you in your battle against depres...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['what', 'be', 'one', 'concrete', 'thing', 'that', 'have', 'help', 'you', 'i...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>does mental health go hand in hand with the physical health?when i feel at m...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['do', 'mental', 'health', 'go', 'hand', 'in', 'hand', 'with', 'the', 'physi...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>the thing that hurts the most is knowing that i have been through worse.when...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['the', 'thing', 'that', 'hurt', 'the', 'most', 'be', 'know', 'that', 'I', '...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>need someone to talk toi am a guy in high school and i just need to talk to ...</td>\n",
              "      <td>depression</td>\n",
              "      <td>['need', 'someone', 'to', 'talk', 'toi', 'be', 'a', 'guy', 'in', 'high', 'sc...</td>\n",
              "      <td>nonsuicide</td>\n",
              "      <td>depression</td>\n",
              "      <td>nonteenager</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac1434ff-3d4e-44e0-a9d0-5503bafce511')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac1434ff-3d4e-44e0-a9d0-5503bafce511 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac1434ff-3d4e-44e0-a9d0-5503bafce511');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-834ebb14-821f-4324-87f0-ad3d689b7974\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-834ebb14-821f-4324-87f0-ad3d689b7974')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-834ebb14-821f-4324-87f0-ad3d689b7974 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12918,\n        \"samples\": [\n          \"i cannot go through with iti have made the decision 4 ti ames, yet every ti ame i seem to back out last minute. i was so sure i would go through with it this ti ame, too. i quit my job, broke up with boyfriend, deleted most of my social media accounts, i was ready to just end it all. yet for some reason i still cannot work up the courage. currently parked off the road next to a bridge because i am scared and do not know what to do.\",\n          \"anyone wanna get married ? bc you can only have sex after marriage  flushed_face \",\n          \"this saturdaythat would be a good day for it. ive finally escaped peoples birthdays, so i neednt worry about that. i just need to get things settled by then.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"SuicideWatch\",\n          \"noise\",\n          \"depression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12908,\n        \"samples\": [\n          \"['at', 'what', 'ti', 'ame', 'do', 'you', 'usually', 'workout', 'personally', 'I', 'just', 'try', 'to', 'be', 'randomly', 'active', 'throughout', 'the', 'day', 'cause', 'I', 'do', 'not', 'know', 'how', 'to', 'focus', 'myself', 'into', 'a', 'workout', 'most', 'of', 'the', 'ti', 'ame', 'which', 'be', 'really', 'I', 'amportant', 'to', 'I', 'because', 'constantly', 'force', 'yourself', 'to', 'do', 'something', 'take', 'a', 'huge', 'toll', 'on', 'your', 'mental', 'health', 'I', 'have', 'try', 'to', 'get', 'into', 'moright', 'nowe', 'workout', 'but', 'I', 'be', 'never', 'feel', 'it', 'or', 'I', 'sleep', 'in', 'usually', 'I', 'start', 'around', 'so', 'I', 'can', 'sleep', 'like', 'the', 'dead', 'even', 'thoughugh', 'they', 'say', 'you', 'should', 'not', 'do', 'that', 'but', 'I', 'be', 'type', 'this', 'at', 'am', 'because', 'I', 'mess', 'up', 'my', 'sleep', 'schedule', 'in', 'the', 'past', 'week', 'I', 'be', 'wonder', 'if', 'I', 'should', 'use', 'this', 'opportunity', 'to', 'try', 'and', 'start', 'a', 'moright', 'nowing', 'routine', 'again']\",\n          \"['anyone', 'wan', 'na', 'make', 'a', 'discord', 'server', 'together', 'it', 'can', 'be', 'about', 'whatever', 'you', 'want', 'I', 'be', 'just', 'that', 'bored', 'really']\",\n          \"['I', 'make', 'this', 'survey', 'on', 'social', 'comparison', 'and', 'in', 'psychology', 'hey', 'I', 'be', 'do', 'an', 'anonymous', 'survey', 'about', 'social', 'comparison', 'and', 'as', 'a', 'task', 'in', 'psychology', 'class', 'I', 'would', 'greatly', 'appreciate', 'if', 'anybody', 'would', 'like', 'to', 'participate', 'thank', 'in', 'advance', 'link', 'https']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"suicide_class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"suicide\",\n          \"nonsuicide\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"depression_class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"nondepression\",\n          \"depression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"teenager_class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"teenager\",\n          \"nonteenager\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "2cjJ-leXT_Ci"
      },
      "outputs": [],
      "source": [
        "def build_cnn_model(vocab_size, embedding_matrix, num_classes):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_len, trainable=True),\n",
        "        Conv1D(128, 5, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_rnn_model(vocab_size, embedding_matrix, num_classes):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_len, trainable=True),\n",
        "        LSTM(128, return_sequences=False),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_bilstm_model(vocab_size, embedding_matrix, num_classes):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_len, trainable=True),\n",
        "        Bidirectional(LSTM(128)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate(model, train_padded, train_labels, test_padded, test_labels,\n",
        "                       class_weights=None, epochs=10, batch_size=32):\n",
        "    f1_callback = F1ScoreCallback(validation_data=(test_padded, test_labels))\n",
        "\n",
        "    model.fit(train_padded, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(test_padded, test_labels),\n",
        "              callbacks=[f1_callback],\n",
        "              class_weight=class_weights)\n",
        "\n",
        "    loss, acc = model.evaluate(test_padded, test_labels)\n",
        "    print(f\"Test Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKZo9e-pR9UD"
      },
      "source": [
        "## Suicide / Non-Suicide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "jNebm64XTRpo"
      },
      "outputs": [],
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"suicide_label\"] = label_encoder.fit_transform(df[\"suicide_class\"])\n",
        "num_classes = len(label_encoder.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs-OLe6209Yo",
        "outputId": "51ee16cf-cab0-445a-c7c0-e3b6de4fa98e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data:  12000\n",
            "Testing data:  4000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Instead of random train test split, stratify by class\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"tokens\"], df[\"suicide_label\"], random_state=64, stratify=df['suicide_label']\n",
        ")\n",
        "print('Training data: ',len(train_texts))\n",
        "print('Testing data: ',len(test_texts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "jCo8KR7TsLpe"
      },
      "outputs": [],
      "source": [
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQe7527viLtq",
        "outputId": "ac0dc422-bd43-4e43-8f9c-6dcb4d9916a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1435     ['anyone', 'else', 'feel', 'like', 'this', 'I', 'have', 'be', 'cope', 'with'...\n",
            "1368     ['lose', 'my', 'sense', 'of', 'realityit', 'be', 'another', 'one', 'of', 'th...\n",
            "5863                                          ['good', 'way', 'to', 'commit', 'suicide']\n",
            "8929     ['I', 'be', 'bakk', 'you', 'lousy', 'son', 'of', 'bitch', 'thoughught', 'I',...\n",
            "15448    ['firstly', 'what', 'be', 'your', 'thoughught', 'on', 'the', 'titular', 'cha...\n",
            "11663    ['just', 'realize', 'how', 'close', 'my', 'teenage', 'year', 'be', 'to', 'fi...\n",
            "3897     ['just', 'a', 'thoughught', 'that', 'enter', 'my', 'mind', 'lie', 'in', 'bed...\n",
            "4635     ['why', 'when', 'I', 'die', 'the', 'world', 'will', 'not', 'stop', 'spin', '...\n",
            "14158    ['we', 'just', 'have', 'our', 'concrete', 'foundation', 'reinforce', 'so', '...\n",
            "13454    ['my', 'wife', 'be', 'italian', 'and', 'my', 'do', 'not', 'speak', 'very', '...\n",
            "Name: tokens, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(train_texts.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqhtvxmjmBQT"
      },
      "source": [
        "### Vectorization/Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "s0da8ceRTxxe"
      },
      "outputs": [],
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "# Padding sequences to have the same length\n",
        "max_len = 200  # Max length for padding\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Vocabulary size\n",
        "vocab_size = len(word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Bi3JxsDHTvF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d86b235b-5c9c-480e-99c5-c6cf38e3b80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ],
      "source": [
        "word2vec_model = gensim.models.Word2Vec(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "fasttext_model = gensim.models.FastText(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "embedding_matrix_w2v = np.zeros((vocab_size, 100))\n",
        "embedding_matrix_ft = np.zeros((vocab_size, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix_w2v[i] = word2vec_model.wv[word]\n",
        "    if word in fasttext_model.wv:\n",
        "        embedding_matrix_ft[i] = fasttext_model.wv[word]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import f1_score\n",
        "class F1ScoreCallback(Callback):\n",
        "    def __init__(self, validation_data):\n",
        "        self.validation_data = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_data, val_labels = self.validation_data\n",
        "        val_preds = self.model.predict(val_data)\n",
        "        val_preds = np.argmax(val_preds, axis=1)  # Convert probabilities to class labels\n",
        "        val_labels = np.argmax(val_labels, axis=1)  # Convert one-hot labels to class labels\n",
        "\n",
        "        f1 = f1_score(val_labels, val_preds, average='weighted')\n",
        "        print(f\" - val_f1: {f1:.4f}\")\n",
        "        logs[\"val_f1\"] = f1"
      ],
      "metadata": {
        "id": "HXNQxOpT3kLr"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Compute class weights\n",
        "weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(df['suicide_label']),\n",
        "    y=df['suicide_label']\n",
        ")\n",
        "class_weights = dict(enumerate(weights))"
      ],
      "metadata": {
        "id": "WD_uwHSCZOd1"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Bi-LSTM with Word2Vec Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels,\n",
        "                   class_weights=class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P48MCOHLZSCi",
        "outputId": "10e90d26-1b2a-466e-8690-4c393bfd3569"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bi-LSTM with Word2Vec Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            " - val_f1: 0.6353\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 24ms/step - accuracy: 0.6674 - loss: 0.5872 - val_accuracy: 0.6155 - val_loss: 0.5263 - val_f1: 0.6353\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.7988\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.7411 - loss: 0.4736 - val_accuracy: 0.7865 - val_loss: 0.4182 - val_f1: 0.7988\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8027\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.8405 - loss: 0.3327 - val_accuracy: 0.7905 - val_loss: 0.4634 - val_f1: 0.8027\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            " - val_f1: 0.8163\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.8850 - loss: 0.2600 - val_accuracy: 0.8067 - val_loss: 0.4375 - val_f1: 0.8163\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            " - val_f1: 0.8257\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9059 - loss: 0.2121 - val_accuracy: 0.8188 - val_loss: 0.4303 - val_f1: 0.8257\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8179\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9268 - loss: 0.1702 - val_accuracy: 0.8165 - val_loss: 0.4842 - val_f1: 0.8179\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8095\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9440 - loss: 0.1362 - val_accuracy: 0.8027 - val_loss: 0.5982 - val_f1: 0.8095\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8160\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9547 - loss: 0.1028 - val_accuracy: 0.8123 - val_loss: 0.6799 - val_f1: 0.8160\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            " - val_f1: 0.6903\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9441 - loss: 0.1423 - val_accuracy: 0.6685 - val_loss: 0.7478 - val_f1: 0.6903\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            " - val_f1: 0.8142\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9364 - loss: 0.1488 - val_accuracy: 0.8125 - val_loss: 0.6891 - val_f1: 0.8142\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8171 - loss: 0.6802\n",
            "Test Accuracy: 0.8125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2P6arsDUH9X",
        "outputId": "ef06ebd6-860d-421b-da27-1117162ebf57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bi-LSTM with Word2Vec Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.7970\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.7742 - loss: 0.5068 - val_accuracy: 0.8087 - val_loss: 0.4039 - val_f1: 0.7970\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            " - val_f1: 0.8007\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.8523 - loss: 0.3402 - val_accuracy: 0.8198 - val_loss: 0.3941 - val_f1: 0.8007\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8211\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.8898 - loss: 0.2538 - val_accuracy: 0.8198 - val_loss: 0.4072 - val_f1: 0.8211\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8190\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - accuracy: 0.9264 - loss: 0.1867 - val_accuracy: 0.8195 - val_loss: 0.4418 - val_f1: 0.8190\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8221\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.9489 - loss: 0.1337 - val_accuracy: 0.8227 - val_loss: 0.5349 - val_f1: 0.8221\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8157\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9541 - loss: 0.1173 - val_accuracy: 0.8170 - val_loss: 0.5540 - val_f1: 0.8157\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            " - val_f1: 0.8024\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9746 - loss: 0.0774 - val_accuracy: 0.7972 - val_loss: 0.6977 - val_f1: 0.8024\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8104\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9814 - loss: 0.0580 - val_accuracy: 0.8102 - val_loss: 0.7958 - val_f1: 0.8104\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            " - val_f1: 0.8086\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9851 - loss: 0.0432 - val_accuracy: 0.8140 - val_loss: 0.9733 - val_f1: 0.8086\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.7892\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.9872 - loss: 0.0366 - val_accuracy: 0.7965 - val_loss: 0.9237 - val_f1: 0.7892\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8030 - loss: 0.9112\n",
            "Test Accuracy: 0.7965\n"
          ]
        }
      ],
      "source": [
        "print(\"Training Bi-LSTM with Word2Vec Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jS-KZPWW4rS",
        "outputId": "4abf1ddf-10ae-44a1-e9af-2fa46453ca4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bi-LSTM with FastText Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8035\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.7773 - loss: 0.4853 - val_accuracy: 0.8198 - val_loss: 0.4000 - val_f1: 0.8035\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            " - val_f1: 0.8355\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.8660 - loss: 0.3100 - val_accuracy: 0.8370 - val_loss: 0.3723 - val_f1: 0.8355\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8296\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.8970 - loss: 0.2428 - val_accuracy: 0.8255 - val_loss: 0.4211 - val_f1: 0.8296\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8196\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9151 - loss: 0.2090 - val_accuracy: 0.8185 - val_loss: 0.4451 - val_f1: 0.8196\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            " - val_f1: 0.8149\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9406 - loss: 0.1542 - val_accuracy: 0.8205 - val_loss: 0.5147 - val_f1: 0.8149\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8108\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9578 - loss: 0.1110 - val_accuracy: 0.8180 - val_loss: 0.6011 - val_f1: 0.8108\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8083\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9749 - loss: 0.0730 - val_accuracy: 0.8060 - val_loss: 0.7156 - val_f1: 0.8083\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8016\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9809 - loss: 0.0513 - val_accuracy: 0.8025 - val_loss: 0.8432 - val_f1: 0.8016\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8044\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9839 - loss: 0.0489 - val_accuracy: 0.7997 - val_loss: 0.8398 - val_f1: 0.8044\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            " - val_f1: 0.7876\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9898 - loss: 0.0324 - val_accuracy: 0.7837 - val_loss: 0.7118 - val_f1: 0.7876\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7853 - loss: 0.7070\n",
            "Test Accuracy: 0.7837\n"
          ]
        }
      ],
      "source": [
        "print(\"Training Bi-LSTM with FastText Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Fi8P_Yw_UdH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00d1e3a8-83e5-406a-fdb2-229c3496ad23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CNN with Word2Vec Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8331\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7714 - loss: 0.5331 - val_accuracy: 0.8385 - val_loss: 0.3439 - val_f1: 0.8331\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8485\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8688 - loss: 0.2904 - val_accuracy: 0.8487 - val_loss: 0.3373 - val_f1: 0.8485\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8425\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9320 - loss: 0.1840 - val_accuracy: 0.8413 - val_loss: 0.3667 - val_f1: 0.8425\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            " - val_f1: 0.8186\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9670 - loss: 0.0978 - val_accuracy: 0.8270 - val_loss: 0.5663 - val_f1: 0.8186\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8230\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9893 - loss: 0.0385 - val_accuracy: 0.8282 - val_loss: 0.6852 - val_f1: 0.8230\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8293\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 0.0189 - val_accuracy: 0.8292 - val_loss: 0.7251 - val_f1: 0.8293\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8258\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.0077 - val_accuracy: 0.8310 - val_loss: 0.9347 - val_f1: 0.8258\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            " - val_f1: 0.8302\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.8303 - val_loss: 0.9078 - val_f1: 0.8302\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8252\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.8232 - val_loss: 0.9241 - val_f1: 0.8252\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8310\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0107 - val_accuracy: 0.8292 - val_loss: 0.9212 - val_f1: 0.8310\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8244 - loss: 0.8992\n",
            "Test Accuracy: 0.8292\n"
          ]
        }
      ],
      "source": [
        "print(\"Training CNN with Word2Vec Embeddings...\")\n",
        "cnn_model = build_cnn_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(cnn_model, train_padded, train_labels, test_padded, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "rdp_PZ8vXCOA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e6b9915-3316-47e9-e580-d59fbb3ff772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CNN with FastText Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8440\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7755 - loss: 0.4949 - val_accuracy: 0.8445 - val_loss: 0.3369 - val_f1: 0.8440\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8407\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8833 - loss: 0.2743 - val_accuracy: 0.8445 - val_loss: 0.3344 - val_f1: 0.8407\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8422\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9321 - loss: 0.1786 - val_accuracy: 0.8440 - val_loss: 0.3954 - val_f1: 0.8422\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8334\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9731 - loss: 0.0870 - val_accuracy: 0.8363 - val_loss: 0.5009 - val_f1: 0.8334\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8384\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9906 - loss: 0.0353 - val_accuracy: 0.8375 - val_loss: 0.5947 - val_f1: 0.8384\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            " - val_f1: 0.8376\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0171 - val_accuracy: 0.8418 - val_loss: 0.7811 - val_f1: 0.8376\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8323\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.8378 - val_loss: 0.8471 - val_f1: 0.8323\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8284\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0091 - val_accuracy: 0.8342 - val_loss: 0.8729 - val_f1: 0.8284\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8366\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9979 - loss: 0.0076 - val_accuracy: 0.8365 - val_loss: 0.9361 - val_f1: 0.8366\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            " - val_f1: 0.8176\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0115 - val_accuracy: 0.8295 - val_loss: 1.0212 - val_f1: 0.8176\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.9564\n",
            "Test Accuracy: 0.8295\n"
          ]
        }
      ],
      "source": [
        "print(\"Training CNN with FastText Embeddings...\")\n",
        "cnn_model = build_cnn_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(cnn_model, train_padded, train_labels, test_padded, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training RNN with Word2Vec Embeddings...\")\n",
        "rnn_model = build_rnn_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(rnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybM6XSBNT2ff",
        "outputId": "b8b78626-9c39-4ae8-b8c0-5a70c9ef68e2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RNN with Word2Vec Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7167\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.7514 - loss: 0.5789 - val_accuracy: 0.7650 - val_loss: 0.5300 - val_f1: 0.7167\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7118\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.7511 - loss: 0.5436 - val_accuracy: 0.7538 - val_loss: 0.5349 - val_f1: 0.7118\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            " - val_f1: 0.7010\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.7932 - loss: 0.4921 - val_accuracy: 0.7535 - val_loss: 0.5326 - val_f1: 0.7010\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7580\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8168 - loss: 0.4601 - val_accuracy: 0.7878 - val_loss: 0.5466 - val_f1: 0.7580\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7190\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8187 - loss: 0.4284 - val_accuracy: 0.7607 - val_loss: 0.5666 - val_f1: 0.7190\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7117\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.8207 - loss: 0.4342 - val_accuracy: 0.7563 - val_loss: 0.6053 - val_f1: 0.7117\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7540\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8308 - loss: 0.4109 - val_accuracy: 0.7725 - val_loss: 0.5136 - val_f1: 0.7540\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8179\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8609 - loss: 0.3049 - val_accuracy: 0.8183 - val_loss: 0.5032 - val_f1: 0.8179\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8221\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9111 - loss: 0.2206 - val_accuracy: 0.8217 - val_loss: 0.5308 - val_f1: 0.8221\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            " - val_f1: 0.8102\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9404 - loss: 0.1600 - val_accuracy: 0.8033 - val_loss: 0.5511 - val_f1: 0.8102\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7937 - loss: 0.5612\n",
            "Test Accuracy: 0.8033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training RNN with FastText Embeddings...\")\n",
        "rnn_model = build_rnn_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(rnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCbMy44KT3Zc",
        "outputId": "38d44b9e-c613-433f-df60-b1069030de11"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RNN with FastText Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            " - val_f1: 0.6920\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.7461 - loss: 0.5696 - val_accuracy: 0.7560 - val_loss: 0.5407 - val_f1: 0.6920\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7306\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7780 - loss: 0.5223 - val_accuracy: 0.7700 - val_loss: 0.5190 - val_f1: 0.7306\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            " - val_f1: 0.7134\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7905 - loss: 0.4934 - val_accuracy: 0.7605 - val_loss: 0.5480 - val_f1: 0.7134\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7131\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8145 - loss: 0.4524 - val_accuracy: 0.7570 - val_loss: 0.5686 - val_f1: 0.7131\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7185\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8231 - loss: 0.4342 - val_accuracy: 0.7575 - val_loss: 0.5690 - val_f1: 0.7185\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7005\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8276 - loss: 0.4219 - val_accuracy: 0.7613 - val_loss: 0.6276 - val_f1: 0.7005\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7060\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.8305 - loss: 0.4113 - val_accuracy: 0.7418 - val_loss: 0.5819 - val_f1: 0.7060\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8128\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8318 - loss: 0.3821 - val_accuracy: 0.8145 - val_loss: 0.4866 - val_f1: 0.8128\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8181\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8995 - loss: 0.2430 - val_accuracy: 0.8127 - val_loss: 0.5215 - val_f1: 0.8181\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8166\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9360 - loss: 0.1669 - val_accuracy: 0.8230 - val_loss: 0.5801 - val_f1: 0.8166\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8272 - loss: 0.5904\n",
            "Test Accuracy: 0.8230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Depression / Non-Depression"
      ],
      "metadata": {
        "id": "0ZYEKPCQfRSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"depression_label\"] = label_encoder.fit_transform(df[\"depression_class\"])\n",
        "num_classes = len(label_encoder.classes_)"
      ],
      "metadata": {
        "id": "5w1LbU5wf_5r"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Instead of random train test split, stratify by class\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"tokens\"], df[\"depression_label\"], random_state=64, stratify=df['depression_label']\n",
        ")"
      ],
      "metadata": {
        "id": "Xj4PsEbphVsq"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "JqB-0wFEhY8W"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorization/Embedding"
      ],
      "metadata": {
        "id": "MZ9L_UFphfMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "# Padding sequences to have the same length\n",
        "max_len = 200  # Max length for padding\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Vocabulary size\n",
        "vocab_size = len(word_index) + 1"
      ],
      "metadata": {
        "id": "dVjANGhBhiyx"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = gensim.models.Word2Vec(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "fasttext_model = gensim.models.FastText(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "embedding_matrix_w2v = np.zeros((vocab_size, 100))\n",
        "embedding_matrix_ft = np.zeros((vocab_size, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix_w2v[i] = word2vec_model.wv[word]\n",
        "    if word in fasttext_model.wv:\n",
        "        embedding_matrix_ft[i] = fasttext_model.wv[word]"
      ],
      "metadata": {
        "id": "P8Ia4s8thpKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d529557a-1d92-4844-eb99-dc7742239ead"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Compute class weights\n",
        "weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(df['depression_label']),\n",
        "    y=df['depression_label']\n",
        ")\n",
        "class_weights = dict(enumerate(weights))"
      ],
      "metadata": {
        "id": "PGeo6fJFZ2kq"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Bi-LSTM with Word2Vec Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "gVe6qK6sik3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9243fae-03e1-4b71-e0ec-494bc227ecc2"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bi-LSTM with Word2Vec Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            " - val_f1: 0.6983\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.7485 - loss: 0.5521 - val_accuracy: 0.7663 - val_loss: 0.4287 - val_f1: 0.6983\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.7454\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.8125 - loss: 0.3875 - val_accuracy: 0.7832 - val_loss: 0.4035 - val_f1: 0.7454\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            " - val_f1: 0.7951\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.8617 - loss: 0.3114 - val_accuracy: 0.7903 - val_loss: 0.4207 - val_f1: 0.7951\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.7811\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.8898 - loss: 0.2411 - val_accuracy: 0.7995 - val_loss: 0.5301 - val_f1: 0.7811\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8099\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9341 - loss: 0.1594 - val_accuracy: 0.8095 - val_loss: 0.4854 - val_f1: 0.8099\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.7863\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9558 - loss: 0.1122 - val_accuracy: 0.8033 - val_loss: 0.7308 - val_f1: 0.7863\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8002\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9716 - loss: 0.0771 - val_accuracy: 0.7965 - val_loss: 0.7168 - val_f1: 0.8002\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            " - val_f1: 0.7972\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9699 - loss: 0.0785 - val_accuracy: 0.7997 - val_loss: 0.7582 - val_f1: 0.7972\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            " - val_f1: 0.7964\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9825 - loss: 0.0510 - val_accuracy: 0.7930 - val_loss: 1.0112 - val_f1: 0.7964\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.7758\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9902 - loss: 0.0283 - val_accuracy: 0.7835 - val_loss: 1.0406 - val_f1: 0.7758\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7777 - loss: 1.0959\n",
            "Test Accuracy: 0.7835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Bi-LSTM with FastText Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "fTah2KHafIt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3bf659-f192-4579-f49b-3e77045877f2"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bi-LSTM with FastText Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            " - val_f1: 0.8157\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.7584 - loss: 0.4828 - val_accuracy: 0.8123 - val_loss: 0.3996 - val_f1: 0.8157\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8259\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.8387 - loss: 0.3430 - val_accuracy: 0.8260 - val_loss: 0.4083 - val_f1: 0.8259\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8140\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.8901 - loss: 0.2453 - val_accuracy: 0.8095 - val_loss: 0.4326 - val_f1: 0.8140\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8101\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9224 - loss: 0.1776 - val_accuracy: 0.8150 - val_loss: 0.4886 - val_f1: 0.8101\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8014\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9425 - loss: 0.1404 - val_accuracy: 0.8048 - val_loss: 0.5474 - val_f1: 0.8014\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.7918\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9607 - loss: 0.1007 - val_accuracy: 0.7983 - val_loss: 0.6595 - val_f1: 0.7918\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            " - val_f1: 0.7756\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9743 - loss: 0.0646 - val_accuracy: 0.7788 - val_loss: 0.7767 - val_f1: 0.7756\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.7906\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9831 - loss: 0.0502 - val_accuracy: 0.7857 - val_loss: 0.9305 - val_f1: 0.7906\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.7996\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9901 - loss: 0.0290 - val_accuracy: 0.8008 - val_loss: 1.1692 - val_f1: 0.7996\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.7988\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9909 - loss: 0.0268 - val_accuracy: 0.8023 - val_loss: 1.1581 - val_f1: 0.7988\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7897 - loss: 1.2358\n",
            "Test Accuracy: 0.8023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training CNN with Word2Vec Embeddings...\")\n",
        "cnn_model = build_cnn_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(cnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "nRK9k2sEfMRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bc05dfe-d738-4d15-e5c9-45cc64a20f4c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CNN with Word2Vec Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8118\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7640 - loss: 0.5119 - val_accuracy: 0.8250 - val_loss: 0.3731 - val_f1: 0.8118\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8317\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8557 - loss: 0.3079 - val_accuracy: 0.8313 - val_loss: 0.3577 - val_f1: 0.8317\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.7970\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9273 - loss: 0.1817 - val_accuracy: 0.8177 - val_loss: 0.5090 - val_f1: 0.7970\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8122\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9737 - loss: 0.0781 - val_accuracy: 0.8185 - val_loss: 0.5397 - val_f1: 0.8122\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8018\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9927 - loss: 0.0265 - val_accuracy: 0.8145 - val_loss: 0.8568 - val_f1: 0.8018\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8148\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0119 - val_accuracy: 0.8175 - val_loss: 0.8434 - val_f1: 0.8148\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8247\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.0029 - val_accuracy: 0.8215 - val_loss: 0.9442 - val_f1: 0.8247\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8160\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.8185 - val_loss: 1.0856 - val_f1: 0.8160\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8177\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.3076e-04 - val_accuracy: 0.8207 - val_loss: 1.1448 - val_f1: 0.8177\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8128\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.2147e-04 - val_accuracy: 0.8195 - val_loss: 1.2412 - val_f1: 0.8128\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 1.3597\n",
            "Test Accuracy: 0.8195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training CNN with FastText Embeddings...\")\n",
        "cnn_model = build_cnn_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(cnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "iVYT0JdefMn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8364c53-014a-4d5e-f3f2-eae0def2cfa6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CNN with FastText Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8059\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 0.5051 - val_accuracy: 0.8192 - val_loss: 0.3744 - val_f1: 0.8059\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8097\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8501 - loss: 0.3223 - val_accuracy: 0.8265 - val_loss: 0.4098 - val_f1: 0.8097\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8290\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9141 - loss: 0.2101 - val_accuracy: 0.8250 - val_loss: 0.4030 - val_f1: 0.8290\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8162\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9683 - loss: 0.0967 - val_accuracy: 0.8188 - val_loss: 0.5211 - val_f1: 0.8162\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8224\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0305 - val_accuracy: 0.8242 - val_loss: 0.6704 - val_f1: 0.8224\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8109\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9972 - loss: 0.0127 - val_accuracy: 0.8202 - val_loss: 0.9459 - val_f1: 0.8109\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.7960\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0039 - val_accuracy: 0.8160 - val_loss: 1.2218 - val_f1: 0.7960\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            " - val_f1: 0.8166\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.8238 - val_loss: 1.1050 - val_f1: 0.8166\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8238\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0018 - val_accuracy: 0.8278 - val_loss: 1.1452 - val_f1: 0.8238\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8114\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.8207 - val_loss: 1.1752 - val_f1: 0.8114\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: 1.3146\n",
            "Test Accuracy: 0.8207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training RNN with Word2Vec Embeddings...\")\n",
        "rnn_model = build_rnn_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(rnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbjPWCHbUENH",
        "outputId": "d20098aa-ddc5-4f78-c14e-eec29c86481d"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RNN with Word2Vec Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7081\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.7384 - loss: 0.6063 - val_accuracy: 0.7670 - val_loss: 0.5211 - val_f1: 0.7081\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7498\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7836 - loss: 0.5123 - val_accuracy: 0.7772 - val_loss: 0.5116 - val_f1: 0.7498\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7355\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8023 - loss: 0.4893 - val_accuracy: 0.7763 - val_loss: 0.5201 - val_f1: 0.7355\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7472\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8225 - loss: 0.4540 - val_accuracy: 0.7812 - val_loss: 0.5400 - val_f1: 0.7472\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            " - val_f1: 0.7442\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.8346 - loss: 0.4286 - val_accuracy: 0.7805 - val_loss: 0.5503 - val_f1: 0.7442\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7450\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8414 - loss: 0.4126 - val_accuracy: 0.7825 - val_loss: 0.5802 - val_f1: 0.7450\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            " - val_f1: 0.7386\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.8493 - loss: 0.3921 - val_accuracy: 0.7755 - val_loss: 0.6119 - val_f1: 0.7386\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7530\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8419 - loss: 0.4038 - val_accuracy: 0.7793 - val_loss: 0.6724 - val_f1: 0.7530\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7931\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8539 - loss: 0.3844 - val_accuracy: 0.7972 - val_loss: 0.5608 - val_f1: 0.7931\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7965\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9051 - loss: 0.2564 - val_accuracy: 0.7970 - val_loss: 0.5796 - val_f1: 0.7965\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7844 - loss: 0.6089\n",
            "Test Accuracy: 0.7970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training RNN with FastText Embeddings...\")\n",
        "rnn_model = build_rnn_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(rnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLrM-KwFUENI",
        "outputId": "99b996a9-d059-43d1-c468-f848e9285bdc"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RNN with FastText Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7230\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.7401 - loss: 0.5572 - val_accuracy: 0.7720 - val_loss: 0.5170 - val_f1: 0.7230\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7443\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.7786 - loss: 0.5214 - val_accuracy: 0.7775 - val_loss: 0.5122 - val_f1: 0.7443\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            " - val_f1: 0.7359\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8144 - loss: 0.4624 - val_accuracy: 0.7778 - val_loss: 0.5287 - val_f1: 0.7359\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7088\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8253 - loss: 0.4464 - val_accuracy: 0.7703 - val_loss: 0.5893 - val_f1: 0.7088\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7762\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.8388 - loss: 0.4153 - val_accuracy: 0.7933 - val_loss: 0.5228 - val_f1: 0.7762\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7946\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8499 - loss: 0.3599 - val_accuracy: 0.7945 - val_loss: 0.4946 - val_f1: 0.7946\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8108\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8980 - loss: 0.2660 - val_accuracy: 0.8102 - val_loss: 0.4776 - val_f1: 0.8108\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8082\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9367 - loss: 0.1696 - val_accuracy: 0.8073 - val_loss: 0.5576 - val_f1: 0.8082\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7919\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9480 - loss: 0.1378 - val_accuracy: 0.8002 - val_loss: 0.6434 - val_f1: 0.7919\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.7908\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9691 - loss: 0.0908 - val_accuracy: 0.7993 - val_loss: 0.7290 - val_f1: 0.7908\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7889 - loss: 0.7635\n",
            "Test Accuracy: 0.7993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teenager / Non-Teenager\n"
      ],
      "metadata": {
        "id": "BowN0hrtgd84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"teenager_label\"] = label_encoder.fit_transform(df[\"teenager_class\"])\n",
        "num_classes = len(label_encoder.classes_)"
      ],
      "metadata": {
        "id": "tb7dCmqJg3sf"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Instead of random train test split, stratify by class\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"tokens\"], df[\"teenager_label\"], random_state=64, stratify=df['teenager_label']\n",
        ")"
      ],
      "metadata": {
        "id": "MdMIisfHTqBf"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "f-lyCsoCTuSs"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorization/Embedding"
      ],
      "metadata": {
        "id": "L7opjK5IjMnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "# Padding sequences to have the same length\n",
        "max_len = 200  # Max length for padding\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Vocabulary size\n",
        "vocab_size = len(word_index) + 1"
      ],
      "metadata": {
        "id": "RLObioXzjP2A"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = gensim.models.Word2Vec(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "fasttext_model = gensim.models.FastText(sentences=train_texts.tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "embedding_matrix_w2v = np.zeros((vocab_size, 100))\n",
        "embedding_matrix_ft = np.zeros((vocab_size, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix_w2v[i] = word2vec_model.wv[word]\n",
        "    if word in fasttext_model.wv:\n",
        "        embedding_matrix_ft[i] = fasttext_model.wv[word]"
      ],
      "metadata": {
        "id": "dN11WPKMjkgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d640813-1df5-4f25-e784-2c88ea879819"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Compute class weights\n",
        "weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(df['teenager_label']),\n",
        "    y=df['teenager_label']\n",
        ")\n",
        "class_weights = dict(enumerate(weights))"
      ],
      "metadata": {
        "id": "gpBLk6UXZ8-M"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Bi-LSTM with Word2Vec Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "kx0b_T0XjmV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9748808-b67e-48f5-bfff-646d0cb8f52a"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bi-LSTM with Word2Vec Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8771\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.8016 - loss: 0.4572 - val_accuracy: 0.8863 - val_loss: 0.2821 - val_f1: 0.8771\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            " - val_f1: 0.9126\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9353 - loss: 0.1992 - val_accuracy: 0.9147 - val_loss: 0.2329 - val_f1: 0.9126\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.9027\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.9687 - loss: 0.1057 - val_accuracy: 0.9070 - val_loss: 0.2623 - val_f1: 0.9027\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            " - val_f1: 0.9070\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9770 - loss: 0.0701 - val_accuracy: 0.9087 - val_loss: 0.2910 - val_f1: 0.9070\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.9109\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.9840 - loss: 0.0507 - val_accuracy: 0.9107 - val_loss: 0.3357 - val_f1: 0.9109\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            " - val_f1: 0.9055\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9905 - loss: 0.0304 - val_accuracy: 0.9090 - val_loss: 0.5480 - val_f1: 0.9055\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            " - val_f1: 0.8962\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9919 - loss: 0.0278 - val_accuracy: 0.9000 - val_loss: 0.4534 - val_f1: 0.8962\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.9025\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9926 - loss: 0.0247 - val_accuracy: 0.9043 - val_loss: 0.5142 - val_f1: 0.9025\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8992\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9943 - loss: 0.0163 - val_accuracy: 0.9030 - val_loss: 0.5552 - val_f1: 0.8992\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            " - val_f1: 0.9045\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9953 - loss: 0.0138 - val_accuracy: 0.9053 - val_loss: 0.4166 - val_f1: 0.9045\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9020 - loss: 0.4488\n",
            "Test Accuracy: 0.9053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Bi-LSTM with FastText Embeddings...\")\n",
        "bilstm_model = build_bilstm_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(bilstm_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "RDGUu-XJfDiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed028a03-d027-4f60-a7c9-cda8eced4cb2"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bi-LSTM with FastText Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.8916\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.8180 - loss: 0.4250 - val_accuracy: 0.8938 - val_loss: 0.2627 - val_f1: 0.8916\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.9100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9280 - loss: 0.2056 - val_accuracy: 0.9100 - val_loss: 0.2329 - val_f1: 0.9100\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.9058\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9620 - loss: 0.1123 - val_accuracy: 0.9047 - val_loss: 0.2673 - val_f1: 0.9058\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            " - val_f1: 0.9140\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9791 - loss: 0.0732 - val_accuracy: 0.9158 - val_loss: 0.3019 - val_f1: 0.9140\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.9116\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9843 - loss: 0.0502 - val_accuracy: 0.9133 - val_loss: 0.3035 - val_f1: 0.9116\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.9100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9860 - loss: 0.0411 - val_accuracy: 0.9125 - val_loss: 0.3542 - val_f1: 0.9100\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.9024\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9929 - loss: 0.0231 - val_accuracy: 0.9022 - val_loss: 0.4198 - val_f1: 0.9024\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            " - val_f1: 0.9052\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9902 - loss: 0.0296 - val_accuracy: 0.9068 - val_loss: 0.4365 - val_f1: 0.9052\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            " - val_f1: 0.9030\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9951 - loss: 0.0147 - val_accuracy: 0.9057 - val_loss: 0.5886 - val_f1: 0.9030\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            " - val_f1: 0.8879\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9971 - loss: 0.0100 - val_accuracy: 0.8848 - val_loss: 0.6852 - val_f1: 0.8879\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8877 - loss: 0.6923\n",
            "Test Accuracy: 0.8848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training CNN with Word2Vec Embeddings...\")\n",
        "cnn_model = build_cnn_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(cnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5KydmbcelRi",
        "outputId": "a7a14fd1-fef3-44d7-bd9f-9b92aafa1f9e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CNN with Word2Vec Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8974\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7617 - loss: 0.5822 - val_accuracy: 0.8985 - val_loss: 0.2596 - val_f1: 0.8974\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9130\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9259 - loss: 0.2030 - val_accuracy: 0.9128 - val_loss: 0.2225 - val_f1: 0.9130\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            " - val_f1: 0.9151\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9754 - loss: 0.0832 - val_accuracy: 0.9160 - val_loss: 0.2381 - val_f1: 0.9151\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9123\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9916 - loss: 0.0303 - val_accuracy: 0.9130 - val_loss: 0.2895 - val_f1: 0.9123\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9040\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 0.0073 - val_accuracy: 0.9032 - val_loss: 0.3851 - val_f1: 0.9040\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9133\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.0030 - val_accuracy: 0.9145 - val_loss: 0.4290 - val_f1: 0.9133\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            " - val_f1: 0.8914\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0027 - val_accuracy: 0.8882 - val_loss: 0.5509 - val_f1: 0.8914\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9127\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9145 - val_loss: 0.5299 - val_f1: 0.9127\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9061\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 5.1368e-04 - val_accuracy: 0.9053 - val_loss: 0.5718 - val_f1: 0.9061\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9093\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9110 - val_loss: 0.6470 - val_f1: 0.9093\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.6540\n",
            "Test Accuracy: 0.9110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training CNN with FastText Embeddings...\")\n",
        "cnn_model = build_cnn_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(cnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "id": "j2biIiiweqaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42856445-1032-44e2-e80d-d6c0bcf3897f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CNN with FastText Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.8911\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7738 - loss: 0.4820 - val_accuracy: 0.8978 - val_loss: 0.2542 - val_f1: 0.8911\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9203\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9420 - loss: 0.1661 - val_accuracy: 0.9218 - val_loss: 0.2047 - val_f1: 0.9203\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9154\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9822 - loss: 0.0625 - val_accuracy: 0.9150 - val_loss: 0.2468 - val_f1: 0.9154\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9135\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 0.0246 - val_accuracy: 0.9162 - val_loss: 0.3262 - val_f1: 0.9135\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9117\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0088 - val_accuracy: 0.9122 - val_loss: 0.3670 - val_f1: 0.9117\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9136\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0054 - val_accuracy: 0.9145 - val_loss: 0.4122 - val_f1: 0.9136\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9098\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0044 - val_accuracy: 0.9125 - val_loss: 0.4977 - val_f1: 0.9098\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9099\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9120 - val_loss: 0.5122 - val_f1: 0.9099\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9096\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0065 - val_accuracy: 0.9130 - val_loss: 0.5318 - val_f1: 0.9096\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " - val_f1: 0.9079\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 0.9118 - val_loss: 0.6227 - val_f1: 0.9079\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.6196\n",
            "Test Accuracy: 0.9118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training RNN with Word2Vec Embeddings...\")\n",
        "rnn_model = build_rnn_model(vocab_size, embedding_matrix_w2v, num_classes)\n",
        "train_and_evaluate(rnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt5pGy19s220",
        "outputId": "578d5985-3272-4f22-f4f2-6a29a5597de1"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RNN with Word2Vec Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            " - val_f1: 0.6429\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.7426 - loss: 0.5432 - val_accuracy: 0.7500 - val_loss: 0.5160 - val_f1: 0.6429\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            " - val_f1: 0.6429\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.7469 - loss: 0.5104 - val_accuracy: 0.7500 - val_loss: 0.5145 - val_f1: 0.6429\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.6429\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7489 - loss: 0.4920 - val_accuracy: 0.7500 - val_loss: 0.5713 - val_f1: 0.6429\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8387\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7732 - loss: 0.4102 - val_accuracy: 0.8390 - val_loss: 0.3763 - val_f1: 0.8387\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            " - val_f1: 0.8632\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8582 - loss: 0.3274 - val_accuracy: 0.8643 - val_loss: 0.3678 - val_f1: 0.8632\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8708\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8900 - loss: 0.2645 - val_accuracy: 0.8745 - val_loss: 0.3215 - val_f1: 0.8708\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8859\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9207 - loss: 0.2111 - val_accuracy: 0.8845 - val_loss: 0.3021 - val_f1: 0.8859\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8903\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9496 - loss: 0.1530 - val_accuracy: 0.8953 - val_loss: 0.3095 - val_f1: 0.8903\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            " - val_f1: 0.8960\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9656 - loss: 0.1138 - val_accuracy: 0.9015 - val_loss: 0.4503 - val_f1: 0.8960\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.9037\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9760 - loss: 0.0782 - val_accuracy: 0.9060 - val_loss: 0.3277 - val_f1: 0.9037\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9074 - loss: 0.3404\n",
            "Test Accuracy: 0.9060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training RNN with FastText Embeddings...\")\n",
        "rnn_model = build_rnn_model(vocab_size, embedding_matrix_ft, num_classes)\n",
        "train_and_evaluate(rnn_model, train_padded, train_labels, test_padded, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iJx7yXJUGPH",
        "outputId": "b4264618-95ff-4635-c60c-b77c922faf64"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RNN with FastText Embeddings...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            " - val_f1: 0.6429\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.7457 - loss: 0.5562 - val_accuracy: 0.7500 - val_loss: 0.5060 - val_f1: 0.6429\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.6429\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.7468 - loss: 0.5090 - val_accuracy: 0.7500 - val_loss: 0.5094 - val_f1: 0.6429\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.6429\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7568 - loss: 0.4820 - val_accuracy: 0.7500 - val_loss: 0.5199 - val_f1: 0.6429\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8376\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.7803 - loss: 0.3936 - val_accuracy: 0.8313 - val_loss: 0.3781 - val_f1: 0.8376\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8623\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8765 - loss: 0.2885 - val_accuracy: 0.8620 - val_loss: 0.3564 - val_f1: 0.8623\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8962\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9248 - loss: 0.1985 - val_accuracy: 0.8957 - val_loss: 0.2782 - val_f1: 0.8962\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.8735\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9611 - loss: 0.1286 - val_accuracy: 0.8692 - val_loss: 0.3475 - val_f1: 0.8735\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.9099\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9714 - loss: 0.1012 - val_accuracy: 0.9110 - val_loss: 0.2894 - val_f1: 0.9099\n",
            "Epoch 9/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.9067\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9837 - loss: 0.0629 - val_accuracy: 0.9097 - val_loss: 0.3702 - val_f1: 0.9067\n",
            "Epoch 10/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            " - val_f1: 0.9105\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9882 - loss: 0.0442 - val_accuracy: 0.9120 - val_loss: 0.3479 - val_f1: 0.9105\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9108 - loss: 0.3488\n",
            "Test Accuracy: 0.9120\n"
          ]
        }
      ]
    }
  ]
}